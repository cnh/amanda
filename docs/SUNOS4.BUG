Return-Path: @uklirb.informatik.uni-kl.de:lott@informatik.uni-kl.de
Received: from mimsy.cs.umd.edu 
	by obelix.cs.UMD.EDU (5.64/UMIACS-0.9/04-05-88)
	id AA19369; Wed, 17 Nov 93 09:24:51 -0500
Received: from stepsun.uni-kl.de 
	by mimsy.cs.UMD.EDU (5.64/UMIACS-0.9/04-05-88)
	id AA12572; Wed, 17 Nov 93 09:23:14 -0500
Received: from uklirb.informatik.uni-kl.de by stepsun.uni-kl.de id as01002;
          17 Nov 93 13:55 MET
Received: from chanel.informatik.uni-kl.de by uklirb.informatik.uni-kl.de
          id aa20831; 17 Nov 93 11:46 MET
Received: from bogner.informatik.uni-kl.de by chanel.informatik.uni-kl.de
          id aa24106; 17 Nov 93 11:44 MET
To: Rusty Wright <rusty@groan.berkeley.edu>
Cc: jds@cs.umd.edu
Subject: revised version of trouble report
Date: Wed, 17 Nov 93 11:44:29 +0100
From: Christopher Lott <lott@informatik.uni-kl.de>
Message-Id:  <9311171144.aa24106@chanel.informatik.uni-kl.de>


Hi,

Here's a revised version of my trouble report.  Please
send it around as you see fit.

chris...

-------------


Subject: Amanda problem "No buffer space available [compress returned 1]"


We first encountered this problem on 23 December 1992, when running
Amanda version 2.0.5 on a Sun ELC using SunOS 4.1.1.  Here are the
conditions under which the problem occurs:

1.  Running some version of SunOS 4.1.x, even with Sun Patch number
    100804-01 (TCP "reset"s can cause an mbuf leak) installed.

2.  The Master host is dumping one of its own partitions to the holding disk.

3.  The partition being dumped is large (e.g., /usr).

4.  The partition is being compressed on its way to the holding disk.

The error message from Amanda after one of these failures looks like this:

    /-- chanel     sd0g lev 0 FAILED [compress returned 1]
    | senddump: start chanel sd0g level 0 to chanel.informatik.uni-kl.de
    |   DUMP: Date of this level 0 dump: Wed Dec 23 15:25:14 1992
    |   DUMP: Date of last level 0 dump: the epoch
    |   DUMP: Dumping /dev/rsd0g (/usr) to standard output
    |   DUMP: mapping (Pass I) [regular files]
    |   DUMP: mapping (Pass II) [directories]
    |   DUMP: estimated 719668 blocks (351.40MB) on 0.23 tape(s).
    |   DUMP: dumping (Pass III) [directories]
    |   DUMP: dumping (Pass IV) [regular files]
    |   DUMP: 7.65% done, finished in 1:00
    ....
    |   DUMP: 95.16% done, finished in 0:03
    |   DUMP: 719668 blocks (351.40MB) on 1 volume
    |   DUMP: DUMP IS DONE
    ? No buffer space available
    | senddump: error [compress returned 1]
    \--------

In response to my first trouble report, Jaime looked at the compress,
library, and kernel code and reported this:

 >  This is not a kernel message, it's printed by compress via perror on a
 >  write error, as near as I can guess.  The message is the text for the errno
 >  value ENOBUFS.  Normally perror prints "<str>: message" but it leaves off
 >  the "<str>: " if <str> is NULL.  When compress gets gets a write error, it
 >  does perror(outname), but outname is null because it is writing to stdout.
 >
 >  ENOBUFS means that there is a problem with allocating mbufs.
 >
 >  The mbuf (memory buffer) is the basic building block of the network
 >  code.  The mbuf data structure is designed to allow efficient buildup and
 >  teardown of packet headers and trailers as the packets pass through the
 >  network layers, without having to repeatedly copy the data around.


Our mediocre workaround was to turn off compression on the affected
partition.  This seemed to solve the problem at first.  The definitive
workaround is not to use the holding disk when dumping large partitions
on the Amanda master, but that is pretty clumsy and causes dumps to run
much longer.

Since the problem's first occurrence we've upgraded to SunOS 4.1.3 and
upgraded the amanda master machine from an ELC to a Sparc10.  The problem
has reappeared several times.  Eventually I patched dump with Jaime's help
to call perror at the point where it was failing (a patch is attached below),
and saw the following message.  Since compress was not being used at that
time, this convinced me that the problem does not lie with the compress
program or the use of the compress program.

    /-- chanel     sd0h lev 0 FAILED [dump returned 3]
    | senddump: start chanel sd0h level 0 to chanel.informatik.uni-kl.de
    |   DUMP: Date of this level 0 dump: Fri Sep 24 01:14:42 1993
    |   DUMP: Date of last level 0 dump: the epoch
    |   DUMP: Dumping /dev/rsd0h (/usr/local) to standard output
    |   DUMP: mapping (Pass I) [regular files]
    |   DUMP: mapping (Pass II) [directories]
    |   DUMP: estimated 603998 blocks (294.92MB) on 0.19 tape(s).
    |   DUMP: dumping (Pass III) [directories]
    |   DUMP: dumping (Pass IV) [regular files]
    |   DUMP: 34.54% done, finished in 0:09
    |   DUMP: write error: No buffer space available
    |   DUMP: Write error on standard output
    |   DUMP: Cannot recover
    |   DUMP: The ENTIRE dump is aborted.
    ? dumper: error [missing size line from dump]
    ? senddump: error [dump returned 3]
    \--------

Well, as it turns out, the error message is misleading.  This problem
is not due to resource exhaustion but rather allocation failure - am
important difference.  Unfortunately, this problem is fiendishly difficult
to reproduce.  Because this problem only occurs on Suns, I think it's a
problem with the SunOS 4 kernel network code.  Below is an extremely
detailed explanation of how I reached this conclusion. 

First idea:  I thought that maybe it's a saved state problem (i.e., need
to reboot regularly).  However, this problem has occurred on a machine
that had been rebooted just an hour before as well as on a machine that
had been running for weeks and had not had this problem in all those
weeks.  So saved state is probably not it.

Then I thought that it really might be a resource exhaustion problem -
simply not enough mbufs out there.  As a possible way of increasing the
mbuf pool, I upped the kernel parameter MAXUSERS to 32, built a new kernel,
and booted the machine on that kernel.  Very shortly thereafter Amanda
choked again with this problem, so that was no help.

To investigate the possibility of exhausting the mbuf pool, I gathered
more data by adding this to bin's crontab:
	# display network memory status once a minute while backups are running
	*  1 * * 2-6 netstat -m | grep network | logger -p local0.err
So netstat was run once a minute while Amanda was running and the data
was gathered in /var/adm/messages.  The output looks like this:
    Nov 16 01:08:01 chanel syslog: 136 Kbytes allocated to network (44% in use)

After collecting many weeks of data, the peak percentage was 96%, pretty
darned high.  However, this is just the raw percentage; i.e., relative
use - here's the exact line:
    Oct 26 01:30:01 chanel syslog: 192 Kbytes allocated to network (96% in use)

I.e., the machine had allocated 192K at that time for mbufs.  A more careful
look at the data revealed that the amount of memory allocated to mbufs is
increased dynamically according to load.  Turned out that 192K was by no
means a maximum.  This explanation is a little long, but stick with me.

First, netstat's output generated immediately after a reboot:

    % netstat -m | cat -n 
	 1  228/256 mbufs in use:
	 2          2 mbufs allocated to packet headers
	 3          94 mbufs allocated to socket structures
	 4          123 mbufs allocated to protocol control blocks
	 5          5 mbufs allocated to routing table entries
	 6          2 mbufs allocated to socket names and addresses
	 7          2 mbufs allocated to interface addresses
	 8  0/16 cluster buffers in use
	 9  48 Kbytes allocated to network (59% in use)
	10  0 requests for memory denied
	11  0 requests for memory delayed
	12  0 calls to protocol drain routines

One can see from line 1 that there were only 48K bytes and 256 mbufs
allocated at that time.  The second critical line is number 10: no mbuf
requests have failed on this machine since it was last rebooted. 

Now look at the netstat output taken after the machine has been up for
a while but with no Amanda failures:

    % netstat -m | cat -n
     1  359/768 mbufs in use:
     2          1 mbufs allocated to data
     3          7 mbufs allocated to packet headers
     4          144 mbufs allocated to socket structures
     5          181 mbufs allocated to protocol control blocks
     6          3 mbufs allocated to routing table entries
     7          20 mbufs allocated to socket names and addresses
     8          1 mbufs allocated to zombie process information
     9          2 mbufs allocated to interface addresses
    10  0/28 cluster buffers in use
    11  124 Kbytes allocated to network (36% in use)
    12  0 requests for memory denied
    13  0 requests for memory delayed
    14  0 calls to protocol drain routines

Ok, I thought, were 124K bytes and 768 mbufs the maximum?  Obviously not,
because at 96% usage there had been 192K bytes allocated.

To investigate this question further and to try to reproduce the problem,
Jaime put together two programs to exercise the socket code in the kernel
in the same way that the amanda code exercises that code.  I attach these
programs below as well in a shar file.  Using these programs I was able
to *exhaust* the supply of mbufs by running 45 parallel reader/writer
pairs; I know the mbuf map was full because this message appeared on
the console:

    Nov 16 09:23:18 chanel vmunix: mbuf map full

Now look at the netstat report after one of these sessions:
 
    % netstat -m | cat -n
	 1  334/3840 mbufs in use:
	 2          4 mbufs allocated to data
	 3          3 mbufs allocated to packet headers
	 4          136 mbufs allocated to socket structures
	 5          169 mbufs allocated to protocol control blocks
	 6          3 mbufs allocated to routing table entries
	 7          15 mbufs allocated to socket names and addresses
	 8          2 mbufs allocated to zombie process information
	 9          2 mbufs allocated to interface addresses
	10  0/24 cluster buffers in use
	11  504 Kbytes allocated to network (8% in use)
	12  152 requests for memory denied
	13  32708 requests for memory delayed
	14  0 calls to protocol drain routines


Look at line 1!  Now 504K bytes and 3,840 mbufs are available!  These
numbers are probably the practical maximums.  This data convinced me
that the machine was not running out of resources when running the
Amanda processes, because even at 96%, there were only 192K allocated,
and I was able to drive it up to nearly 3 times that amount by using
the test programs.  Also note that although many requests have been
denied, even more have been delayed.  So it looks like the kernel code
works, at least sometimes.  

Finally, the interesting data from netstat.  After one of these Amanda
failures, the netstat output from the master machine looks like this:

    % netstat -m | cat -n 
	 1  331/832 mbufs in use:
	 2          1 mbufs allocated to data
	 3          4 mbufs allocated to packet headers
	 4          134 mbufs allocated to socket structures
	 5          168 mbufs allocated to protocol control blocks
	 6          3 mbufs allocated to routing table entries
	 7          16 mbufs allocated to socket names and addresses
	 8          3 mbufs allocated to zombie process information
	 9          2 mbufs allocated to interface addresses
	10  0/16 cluster buffers in use
	11  120 Kbytes allocated to network (34% in use)
	12  1 requests for memory denied
	13  0 requests for memory delayed
	14  0 calls to protocol drain routines


Look at line 12: a single request was denied.  Not delayed but instead
denied.  **This is the problem.**  Clearly there's plenty of room for
more mbufs, so it's not a resource exhaustion problem.

So to repeat my conclusion, I think we're dealing with a nasty kernel
bug in the network code, very difficult to reproduce, possibly related
to timing or the phase of the moon or something even stranger.  If it
were easy to reproduce, I would have already taken it up with Sun. 
Because this problem is restricted to SunOS 4.1.x, Sun probably is not
willing to devote significant attention to it.  And even worse, causing
a single denial instead of a delay is difficult to reproduce on demand.

Hope that this helps.

chris...

Attached below: the dump patch and the programs to exercise the kernel.

-----patch-----
% diff -c dumptape.c.orig dumptape.c
*** dumptape.c.orig     Wed Jun  5 18:17:23 1991
--- dumptape.c  Thu Sep 23 11:27:03 1993
***************
*** 640,645 ****
--- 640,646 ----
        int nread;
        char *rbuf;
        long archivesize, size;
+       int rc;
  
        if (doingverify) {
                rbuf = (char *)malloc((u_int)writesize);
***************
*** 713,721 ****
                                }
                        } else {
                                if (!doingverify) {
!                                       if (write(to, tp, writesize) ==
                                            writesize)
                                                continue;
                                } else {
                                        if (read(to, rbuf, writesize) ==
                                            writesize &&
--- 714,726 ----
                                }
                        } else {
                                if (!doingverify) {
!                                       if ((rc = write(to, tp, writesize)) ==
                                            writesize)
                                                continue;
+                                       if (rc == -1) 
+                                               perror("  DUMP: write error");
+                                       else
+                                               msg("short write: expected %d g
to %d\n", writesize, rc);
                                } else {
                                        if (read(to, rbuf, writesize) ==
                                            writesize &&
-----patch-----



#!/bin/sh
# This is a shell archive (produced by shar 3.49)
# To extract the files from this archive, save it to a file, remove
# everything above the "!/bin/sh" line above, and type "sh file_name".
#
# made 11/16/1993 08:26 UTC by lott@chanel
# Source directory /a/bogner/home/bogner/lott/tmp/amtest
#
# existing files will NOT be overwritten unless -c is specified
#
# This shar contains:
# length  mode       name
# ------ ---------- ------------------------------------------
#    235 -rw-r--r-- Makefile
#   3264 -rw-r--r-- source.c
#   2379 -rw-r--r-- sink.c
#    511 -rwxr-xr-x test.sh
#
# ============= Makefile ==============
if test -f 'Makefile' -a X"$1" != X"-c"; then
	echo 'x - skipping Makefile (File already exists)'
else
echo 'x - extracting Makefile (Text)'
sed 's/^X//' << 'SHAR_EOF' > 'Makefile' &&
CC=gcc
CFLAGS=-g -Wall
X
all: source sink
X
source: source.c
X	$(CC) $(CFLAGS) -o source source.c
X
sink: sink.c
X	$(CC) $(CFLAGS) -o sink sink.c
X
shar:
X	shar Makefile source.c sink.c test.sh > amtest.shar
X
clean:
X	rm -f sink source *.o *~
SHAR_EOF
chmod 0644 Makefile ||
echo 'restore of Makefile failed'
Wc_c="`wc -c < 'Makefile'`"
test 235 -eq "$Wc_c" ||
	echo 'Makefile: original size 235, current size' "$Wc_c"
fi
# ============= source.c ==============
if test -f 'source.c' -a X"$1" != X"-c"; then
	echo 'x - skipping source.c (File already exists)'
else
echo 'x - extracting source.c (Text)'
sed 's/^X//' << 'SHAR_EOF' > 'source.c' &&
/* source.c - data source for socket */
#include <stdio.h>
#include <string.h>
#include <errno.h>
X
#include <sys/types.h>
#include <sys/time.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <netdb.h>
X
char pname[40];
X
void usage()
{
X    fprintf(stderr, 
X    "Usage: source <id> <hostname> <port> <writesize> <socksize> <nblocks>\n");
X    exit(1);
}
X
void main(argc, argv)
int argc;
char **argv;
{
X    char *hostname, *buffer, *malloc();
X    int id, port, sock, writesize, socksize, nblocks, size, i, rc;
X    double kbytes, secs;
X    struct sockaddr_in peer;
X    struct hostent *hostp;
X    struct timeval start_time, end_time, run_time;
X    struct timezone tz;
X
X    if(argc < 7) usage();
X    id = atoi(argv[1]);
X    hostname = argv[2];
X    port = atoi(argv[3]);
X    writesize = atoi(argv[4]);
X    socksize = atoi(argv[5]);
X    nblocks = atoi(argv[6]);
X
X    sprintf(pname, "source%d", id);
X
X    /* set up remote address */
X
X    if((hostp = gethostbyname(hostname)) == NULL) {
X	fprintf(stderr, "hostname %s not recognized", hostname);
X	exit(1);
X    }
X
X    memset(&peer, 0, sizeof(peer));
X    peer.sin_family = AF_INET;
X    peer.sin_port = htons(port);
X    memcpy(&peer.sin_addr, hostp->h_addr, hostp->h_length);
X
X    fprintf(stderr, "%s: connecting to %s port %d\n", pname, hostname, port);
X    fprintf(stderr, "%s: writesize %d socksize %d blocks %d\n",
X	    pname, writesize, socksize, nblocks);
X
X    /* connect */
X
X    if((sock = socket(AF_INET, SOCK_STREAM, 0)) == -1) {
X	perror("socket");
X	exit(1);
X    }
X
X    if(connect(sock, (struct sockaddr *)&peer, sizeof(peer)) == -1) {
X	perror("connect");
X	exit(1);
X    }
X
X    /* set socket buffer size */
X
X    if(socksize != -1) {
X	size = socksize;
X	while(size > 1024 &&
X	     setsockopt(sock, SOL_SOCKET, SO_SNDBUF, &size, sizeof(int)) < 0)
X	    size -= 1024;
X	if(size < socksize)
X	    fprintf(stderr, "%s: had to settle for %d byte send buf", 
X		    pname, size);
X    }
X
X    /* generate random data buffer */
X
X    if((buffer = malloc(writesize)) == NULL) {
X	fprintf(stderr, "%s: could not malloc %d byte write buffer\n",
X		pname, writesize);
X	exit(1);
X    }
X
X    for(i=0;i<writesize;i++) buffer[i] = random();
X
X    gettimeofday(&start_time, &tz);
X
X    if(nblocks == -1)
X	while((rc = write(sock, buffer, writesize)) == writesize);
X    else
X	for(i = 0; 
X	    (i < nblocks) && ((rc = write(sock,buffer,writesize)) == writesize);
X	    i++);
X
X    gettimeofday(&end_time, &tz);
X
X    /* check if the last write was successful and react appropriately */
X    if(rc == writesize) {
X	fprintf(stderr, "%s: completed successfully.\n", pname);
X    }
X    else if (rc >= 0) {
X	fprintf(stderr, "%s: SHORT WRITE: EXPECTED %d, GOT %d\n",
X		pname, writesize, rc);
X	exit(1);
X	}
X    else {
X	fprintf(stderr, "%s: WRITE ERROR\n", pname);
X	perror(pname);
X	exit(2);
X    }
X
X    run_time.tv_usec = end_time.tv_usec - start_time.tv_usec;
X    run_time.tv_sec = end_time.tv_sec - start_time.tv_sec;
X    if(run_time.tv_usec < 0) {
X	run_time.tv_usec += 1000000;
X	run_time.tv_sec -= 1;
X    }
X
X    kbytes = writesize/1024.0*nblocks;
X    secs = run_time.tv_sec + run_time.tv_usec/1000000;
X
X    fprintf(stderr, "%s: %1.0f kb written in %1.3f seconds, %1.2f kps\n",
X	    pname, kbytes, secs, secs == 0.0? 0.0 : kbytes/secs);
X	    
X    exit(0);
}
SHAR_EOF
chmod 0644 source.c ||
echo 'restore of source.c failed'
Wc_c="`wc -c < 'source.c'`"
test 3264 -eq "$Wc_c" ||
	echo 'source.c: original size 3264, current size' "$Wc_c"
fi
# ============= sink.c ==============
if test -f 'sink.c' -a X"$1" != X"-c"; then
	echo 'x - skipping sink.c (File already exists)'
else
echo 'x - extracting sink.c (Text)'
sed 's/^X//' << 'SHAR_EOF' > 'sink.c' &&
/* sink.c - data sink from socket */
#include <stdio.h>
#include <string.h>
#include <errno.h>
X
#include <sys/types.h>
#include <sys/time.h>
#include <sys/socket.h>
#include <netinet/in.h>
#include <netdb.h>
X
char pname[40];
X
void usage()
{
X    fprintf(stderr, "Usage: sink <id> <socksize>\n");
X    exit(1);
}
X
void main(argc, argv)
int argc;
char **argv;
{
X    char *buffer, *malloc();
X    int id, port, sock, conn;
X    int socksize, size, i, rc;
X    struct sockaddr_in myaddr, peeraddr;
X
X    if(argc < 3) usage();
X    id = atoi(argv[1]);
X    socksize = atoi(argv[2]);
X
X    sprintf(pname, "sink%d", id);
X
X    /* set up socket */
X
X    if((sock = socket(AF_INET, SOCK_STREAM, 0)) == -1) {
X	perror("socket");
X	puts("-1");
X	exit(1);
X    }
X
X    memset(&myaddr, 0, sizeof(myaddr));
X    myaddr.sin_family = AF_INET;
X    myaddr.sin_addr.s_addr = INADDR_ANY;
X
X    /* pick any available non-reserved port */
X
X    myaddr.sin_port = htons(0);
X
X    if(bind(sock, (struct sockaddr *)&myaddr, sizeof(myaddr)) == -1) {
X	perror("bind");
X	puts("-1");
X	exit(1);
X    }
X
X    /* find out what the address was */
X
X    i = sizeof(myaddr);
X    if(getsockname(sock, (struct sockaddr *)&myaddr, &i) == -1) {
X	perror("getsockname");
X	puts("-1");
X	exit(1);
X    }
X    port = (int) ntohs(myaddr.sin_port);
X
X    printf("%d\n", port);
X    switch(fork()) {
X    case -1:	
X	perror("fork"); exit(1);
X    case 0:	
X	break;
X    default:	
X	exit(0);
X    }
X    fprintf(stderr, "%s: pid %d waiting on port %d\n", pname, getpid(), port);
X    close(0);
X    close(1);
X
X    /* wait for connect */
X
X    listen(sock, 1);
X    i = sizeof(peeraddr);
X    if((conn = accept(sock, &peeraddr, &i)) == -1) {
X	perror("accept");
X	exit(1);
X    }
X
X    /* set socket buffer size */
X
X    if(socksize != -1) {
X	size = socksize;
X	while(size > 1024 &&
X	     setsockopt(conn, SOL_SOCKET, SO_SNDBUF, &size, sizeof(int)) < 0)
X	    size -= 1024;
X	if(size < socksize)
X	    fprintf(stderr, "%s: had to settle for %d byte send buf", 
X		    pname, size);
X    }
X
X    /* gobble up the data */
X
X    if((buffer = malloc(socksize)) == NULL) {
X	fprintf(stderr, "%s: could not malloc %d byte read buffer\n",
X		pname, socksize);
X	exit(1);
X    }
X
X    while((rc = read(conn, buffer, socksize)) > 0);
X
X    if(rc == 0)
X	fprintf(stderr, "%s: completed successfully.\n", pname);
X    else {
X	fprintf(stderr, "%s: read error", pname);
X	perror("");
X    }
X    exit(0);
}
SHAR_EOF
chmod 0644 sink.c ||
echo 'restore of sink.c failed'
Wc_c="`wc -c < 'sink.c'`"
test 2379 -eq "$Wc_c" ||
	echo 'sink.c: original size 2379, current size' "$Wc_c"
fi
# ============= test.sh ==============
if test -f 'test.sh' -a X"$1" != X"-c"; then
	echo 'x - skipping test.sh (File already exists)'
else
echo 'x - extracting test.sh (Text)'
sed 's/^X//' << 'SHAR_EOF' > 'test.sh' &&
#!/bin/sh
X
nparallel=50
ksock=32
kwrite=32
megtotal=3
X
socksize=`expr $ksock \* 1024`
writesize=`expr $kwrite \* 1024`
nblocks=`expr $megtotal \* 1024 \* 1024 / $writesize`
hostname=`hostname`
X
echo testing nblocks $nblocks socksize $socksize writesize $writesize hostname $hostname
X
i=0
while [ $i -lt $nparallel ] ; do
X	port=`./sink $i $socksize`
X	if [ $port -lt 0 ]; then
X		echo "sink$i got an error, stopping."
X		exit 1
X	fi
X	./source $i $hostname $port $writesize $socksize $nblocks &
X	i=`expr $i + 1`
done
SHAR_EOF
chmod 0755 test.sh ||
echo 'restore of test.sh failed'
Wc_c="`wc -c < 'test.sh'`"
test 511 -eq "$Wc_c" ||
	echo 'test.sh: original size 511, current size' "$Wc_c"
fi
exit 0
